{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-9: Convolutions and CNN\n",
    "\n",
    "In this lab, you will practice convolutional operation and how to implement CNN using keras and tensorflow.\n",
    "\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "1. Convolutions - application examples:\n",
    "    - edge detection    \n",
    "    - negation\n",
    "    - blurring\n",
    "    - sharpening\n",
    "2. Building CNN in PyTorch / Keras / Tensorflow\n",
    "    - example CNN\n",
    "    - comparing with Fully-connected NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "1. What is the use of convolutions? (In general)\n",
    "2. Why use convolutional layers instead of fully-connected ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "Let's upload some image (you can try your own image changing the url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"https://res-2.cloudinary.com/crunchbase-production/image/upload/c_lpad,h_256,w_256,f_auto,q_auto:eco/lss423kothpqpjpwbzg0\"\n",
    "filename = 'grid_img.jpg'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np\n",
    "\n",
    "# Let's read and plot the image\n",
    "image = plt.imread('grid_img.jpg')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = rgb2gray(image)\n",
    "plt.imshow(gray_image * 100, cmap='gray')\n",
    "print(\"original img shape: \", image.shape)\n",
    "print(\"grayscale img shape\", gray_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's define edge-detecting filters\n",
    "horizontal_kernel = np.array([[1, 1, 1], \n",
    "                              [0, 0, 0], \n",
    "                              [-1, -1, -1]])\n",
    "print(horizontal_kernel, 'is a kernel for detecting horizontal edges')\n",
    " \n",
    "vertical_kernel = np.array([[-1, 0, 1], \n",
    "                            [-1, 0, 1], \n",
    "                            [-1, 0, 1]])\n",
    "print(vertical_kernel, 'is a kernel for detecting vertical edges')\n",
    "\n",
    "out_h = ndimage.convolve(gray_image, horizontal_kernel, mode='reflect')\n",
    "out_v = ndimage.convolve(gray_image, vertical_kernel, mode='reflect')\n",
    "plt.imshow(out_h)\n",
    "#plt.imshow(out_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply different types of convolutions on this image. Complete the following function.\n",
    "\n",
    "Take care of dimensions - the resuting image should be of the same size.\n",
    "Hint:\n",
    "\n",
    "![alt text](https://i.gyazo.com/5265866b07235dfa181de39913e94713.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(img, kernel):\n",
    "    result = np.zeros(img.shape)\n",
    "        # apply kernel on input image such that the image size is preserved\n",
    "        return result\n",
    "\n",
    "c = convolve(gray_image, horizontal_kernel)\n",
    "print(\"Horizontal kernel applied\")\n",
    "plt.imshow(c, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = convolve(gray_image, vertical_kernel)\n",
    "print(\"Vertical kernel applied\")\n",
    "plt.imshow(c, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the kernel affects the output result.\n",
    "For this, we should set various values on the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with numbers, see how changing the kernel affects the result\n",
    "your_kernel = np.array([[0, 0, 0], \n",
    "                        [0, 0, 0], \n",
    "                        [0, 0, 0]])\n",
    "\n",
    "c = convolve(gray_image, your_kernel)\n",
    "print(\"Your kernel applied\")\n",
    "plt.imshow(c, cmap='gray')\n",
    "\n",
    "some_kernel = np.array([[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel that will result in reversed image, in which the lightest areas of\n",
    "# the photographed subject appear darkest and the darkest areas appear the lightest.\n",
    "negative_kernel = None\n",
    "\n",
    "c = convolve(gray_image, negative_kernel)\n",
    "print(\"Negative kernel applied\")\n",
    "plt.imshow(c, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel that will result in a blurred image\n",
    "# How can we control the degree of blur?\n",
    "\n",
    "blur_kernel = None\n",
    "\n",
    "#simple sum\n",
    "blur_kernel2 = np.ones((11,11))\n",
    "\n",
    "c_blurred = convolve(gray_image, blur_kernel)\n",
    "print(\"Blur kernel applied\")\n",
    "plt.imshow(c_blurred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's sharpen the blurred image back \n",
    "sharpen_kernel = None\n",
    "\n",
    "c = convolve(c_blurred, sharpen_kernel)\n",
    "print(\"Sharpen kernel applied\")\n",
    "plt.imshow(c, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the ANN on the  MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  load the MNIST dataset again (since we made some changes on the previously loaded dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train_digit, y_train_digit), (X_test_digit, y_test_digit) = datasets.mnist.load_data()\n",
    "\n",
    "X_train_digit = X_train_digit.reshape(60000, 784)\n",
    "X_test_digit = X_test_digit.reshape(10000, 784)\n",
    "\n",
    "\n",
    "#Encoding the Labels\n",
    "y_train_digit = keras.utils.to_categorical(y_train_digit, num_classes=10)\n",
    "\n",
    "y_test_digit = keras.utils.to_categorical(y_test_digit, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create ANN with the following architecture:\n",
    "\n",
    "-> Dense ( where input=784 and with 128 units)\n",
    "\n",
    "-> Dense with 24 units, with activation function relu\n",
    "\n",
    "-> Dense with 24 units, with activation function relu\n",
    "\n",
    "-> Dense with 10 units, with activation function sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating base neural network\n",
    "model = keras.Sequential([\n",
    "    # add layers here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the ANN on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train_digit, y_train_digit, batch_size=100, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the diagram which shows the progress in loss of the model during the train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the diagram which shows the progress of the model with regard to its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test_digit, y_test_digit, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can judge from the results, the ANN has around 104K params and we spent 20 epochs on achieving such an accuracy.\n",
    "\n",
    "Now let's see how CNN could solve such problems easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN using PyTorch\n",
    "\n",
    "First, let's import the torch library, and we will also try to set the device to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get familiar with dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get familiar with the shapes of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train dataset shape: {train_data.data.size()}\")\n",
    "print(f\"target shape: {train_data.targets.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of MNIST dataset\n",
    "\n",
    "Let's plot one single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_data.data[0], cmap='gray')\n",
    "plt.title('%i' % train_data.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for training with DataLoaders\n",
    "\n",
    "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
    "\n",
    "DataLoader is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Regarding Conv2d\n",
    "- 1.1  What is the main responsibility of the Conv2D layer?\n",
    "\n",
    "- 1.2 What does filters number mean?\n",
    "- 1.3 How can we interpret the kernel size? \n",
    "- 1.4 What is the purpose of the relu actiation in Conv2D?\n",
    "\n",
    "#### 2. Regarding MaxPooling\n",
    "- 2.1 Why do we use MaxPooling2D in CNN?\n",
    "\n",
    "#### 3. Regarding  Flatten\n",
    "\n",
    "-  3.1 What is the purpose of the Flatten layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The modules / classes in torch for CNN\n",
    "\n",
    "Conv2d: Applies a 2D convolution over an input signal composed of several input planes.\n",
    "\n",
    "Parameters\n",
    "\n",
    "- in_channels (int) — Number of channels in the input image\n",
    "\n",
    "- out_channels (int) — Number of channels produced by the convolution\n",
    "\n",
    "- kernel_size (int or tuple) — Size of the convolving kernel\n",
    "\n",
    "- stride (int or tuple, optional) — Stride of the convolution. Default: 1\n",
    "\n",
    "- padding (int or tuple, optional) — Zero-padding added to both sides of the input. Default: 0\n",
    "\n",
    "- padding_mode (string, optional) — ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’\n",
    "\n",
    "- dilation (int or tuple, optional) — Spacing between kernel elements. Default: 1\n",
    "\n",
    "- groups (int, optional) — Number of blocked connections from input channels to output channels. Default: 1\n",
    "\n",
    "- bias (bool, optional) — If True, adds a learnable bias to the output. Default: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a CNN using torch Module with the following architecture:\n",
    "\n",
    "-> Conv2d where in_channels =1, out_channels=16, kernel size 5, stride 1 and padding 2\n",
    "\n",
    "-> Relu\n",
    "\n",
    "-> MaxPool2d with kernel size 2\n",
    "\n",
    "-> Conv2d where in_channels = 16, out_channels=32, kernel size 5, stride 1 and padding 2\n",
    "\n",
    "-> Relu\n",
    "\n",
    "-> MaxPool2d with kernel size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # add layers here\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenting on the above mode:\n",
    "\n",
    "- in_channels=1: because our input is a grayscale image.\n",
    "\n",
    "- Stride: is the number of pixels to pass at a time when sliding the convolutional kernel.\n",
    "\n",
    "- Padding: to preserve exactly the size of the input image, it is useful to add a zero padding on the border of the image.\n",
    "\n",
    "- kernel_size: we need to define a kernel which is a small matrix of size 5 * 5. To perform the convolution operation, we just need to slide the kernel along the image horizontally and vertically and do the dot product of the kernel and the small portion of the image.\n",
    "\n",
    "- The forward() pass defines the way we compute our output using the given layers and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the model based on the architecture specified in the above class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()   \n",
    "loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Function\n",
    "\n",
    "Now we will define optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's time to train the model!\n",
    "\n",
    "Create a function called train() and pass num of epochs, model and data loaders as input parameters.\n",
    "\n",
    "num_epochs: Number of times our model will go through the entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "\n",
    "    cnn.train()\n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "\n",
    "            output = cnn(b_x)[0]\n",
    "            loss = loss_func(output, b_y)\n",
    "\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backpropagation, compute gradients\n",
    "            loss.backward()\n",
    "            # apply gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "train(num_epochs, cnn, loaders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data\n",
    "\n",
    "We must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference.\n",
    "\n",
    "model.train() tells your model that you are training the model. So effectively layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly.\n",
    "\n",
    "You can call either model.eval() or model.train(mode=False) to tell that you are testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            pass\n",
    "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN using Keras in Tensorflow platform\n",
    "\n",
    "First, we will load the required libraries. The keras library on top of the tensorflow will be utilized.\n",
    "\n",
    "Keras and TensorFlow are both open-source software. TensorFlow is a software library for machine learning. Keras runs on top of TensorFlow and expands the capabilities of the base machine-learning software. Keras also makes implementation, testing, and usage more user-friendly.\n",
    "\n",
    "Keras works with TensorFlow to provide an interface in the Python programming language. It works by using layers and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will be experimenting the CNN technique on the MNIST (http://yann.lecun.com/exdb/mnist/) dataset which has 60,000 and 10,000 rows for the train and test sets, respectively.\n",
    "\n",
    "Using keras library, we can load the MNIST dataset directly from the datasets package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset is an important phase. So we will get familiar with different aspects of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train.shape: ', x_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('x_test.shape: ', x_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of the libraries and frameworks that work with image expect the input data to be in 4 dimension ($batch\\_size \\times height \\times width \\times channel\\_for\\_colors$) in order to support colored images as well, we should also add another dimension to our dataset to make it 4-dimensional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get familiar with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_y_train = pd.DataFrame(y_train)\n",
    "df_y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the labels just digits from 0 to 9.\n",
    "\n",
    "To get visualised information about the dataset, let's plot some of the elements. \n",
    "For that, we will create a function which will plot an image with its label (digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(X, Y):\n",
    "    for i in range(20):\n",
    "        plt.subplot(5, 4, i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title('Digit: {}'.format(Y[i]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values of the dataset (x_train and x_test) lie between [0,255], we should normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write two lines of code that will make the pixels lie between [0, 255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the labels into binary class matricies, since we saw earlier that the labels are just in digits format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the sequental model of the keras for adding the layers of the CNN one by one.\n",
    "\n",
    "The Sequential model should have the following architecture:\n",
    "\n",
    "-> Input with shape $[128 \\times 128 \\times 1]$\n",
    "\n",
    "-> Conv2D (32 filters; kernel size is $[3 \\times 3]$; activation function is relu ) \n",
    "\n",
    "-> MaxPooling2D layer with pool size $[2 \\times 2]$\n",
    "\n",
    "-> Conv2D (64 filters; kernel size is $[3 \\times 3]$; activation function is relu ) \n",
    "\n",
    "-> MaxPooling2D layer with pool size $[2 \\times 2]$\n",
    "\n",
    "-> Flatten\n",
    "\n",
    "-> Dense layer with the softmax activation function (you should also specify the number of output classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the CNN model with the given architecture above\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the training process.  Before that, we should config the model with losses and metrics with model.compile()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "# todo: write one line of code to compile the model with:\n",
    "#   - the categorical_crossentropy loss function\n",
    "#   - use adam as optimizer\n",
    "#   - use 'accuracy' as metrics\n",
    "\n",
    "\n",
    "# todo: write one line of code to train the model:\n",
    "#   - set the size of the batch size\n",
    "#   - also, set train / validation dataset split as 90 / 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the diagram which shows the progress in loss of the model during the train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the diagram which shows the progress of the model with regard to its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can judge from the results, the CNN (in case of Tensorflow) achieved higher accuracy with less number of parameters (~ 32K) and in less epochs, while the ANN has around 104K params and we spent 20 epochs on achieving less accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "- https://phoenixnap.com/kb/how-to-install-keras-on-linux\n",
    "- https://www.quora.com/What-is-the-meaning-of-a-filter-size-in-a-CNN\n",
    "- https://stats.stackexchange.com/questions/363190/why-we-use-activation-function-after-convolution-layer-in-convolution-neural-net\n",
    "- https://medium.com/analytics-vidhya/applying-ann-digit-and-fashion-mnist-13accfc44660"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6df0ddd77085922c773681b1c23afa6ec355a7eb5a25c833f534ec75c0111436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
